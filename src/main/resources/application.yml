spring:
  mvc:
    static-path-pattern: /**
  web:
    resources:
      static-locations: classpath:/META-INF/resources/

  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://localhost:3306/loganalysis?characterEncoding=utf8&nullCatalogMeansCurrent=true&useSSL=false&useUnicode=true&0=true&useLegacyDatetimeCode=false&serverTimezone=Asia/Shanghai
    username: root
    password: MySqlPassword!!

  kafka:
    ###########【Kafka集群】###########
    bootstrap-servers: 123.249.42.58:9092

    ###########【初始化生产者配置】###########
    producer:
      retries: 0
      acks: 1
      # 当生产端积累的消息达到batch-size或接收到消息linger.ms后,生产者就会将消息提交给kafka
      batch-size: 16384
      properties:
        linger:
          ms: 0
          # 自定义分区器
          #partitioner:
          #class: com.felix.kafka.producer.CustomizePartitioner
      buffer-memory: 33554432
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer

    ###########【初始化消费者配置】###########
    # 消费端监听的topic不存在时，项目启动会报错(关掉)
    listener:
      missing-topics-fatal: false
      # 设置批量消费
      type: batch

    consumer:
      properties:
        # 默认的消费组ID
        group:
          id: defaultConsumerGroupLocal
        # 消费会话超时时间(超过这个时间consumer没有发送心跳,就会触发rebalance操作)
        session:
          timeout:
            ms: 120000
        # 消费请求超时时间
        request:
          timeout:
            ms: 120000
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 是否自动提交offset
      #enable-auto-commit: true
      #auto-offset-reset: latest
      # 批量消费每次最多消费多少条消息
      max-poll-records: 50


mybatis-plus:
  mapper-locations: classpath:mapper/*.xml
    # 控制台打印sql语句
    #configuration:
  #log-impl: org.apache.ibatis.logging.stdout.StdOutImpl
